{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Try the New MCP Agent - connected to a Test Postgres DB\n",
        "\n",
        "### Features include:\n",
        "\n",
        "- 🔍 Database Health - analyze index health, connection utilization, buffer cache, vacuum health, sequence limits, replication lag, and more.\n",
        "- ⚡ Index Tuning - explore thousands of possible indexes to find the best solution for your workload, using industrial-strength algorithms.\n",
        "- 📈 Query Plans - validate and optimize performance by reviewing EXPLAIN plans and simulating the impact of hypothetical indexes.\n",
        "- 🧠 Schema Intelligence - context-aware SQL generation based on detailed understanding of the database schema.\n",
        "- 🛡️ Safe SQL Execution - configurable access control, including support for read-only mode and safe SQL parsing, making it usable for both development and production."
      ],
      "metadata": {
        "id": "Cvp4SJpJntY9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UFHS0ukAn-2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjnxV_L4xYKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e3375c-4c46-460e-cfc1-7b5a0117d91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -q langchain-mcp-adapters langgraph langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q psycopg2-binary"
      ],
      "metadata": {
        "id": "uVrF5e8T9rIb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd9f320-cb03-4b91-cf44-4ad5540cb2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/3.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/3.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_url = \"your_hosted_postgres_db_connection_url\""
      ],
      "metadata": {
        "id": "FfeEn29L-I2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't run this as data is already loaded in the DB\n",
        "# this code is used to load the sample data to the db\n",
        "\n",
        "# import psycopg2\n",
        "# import requests\n",
        "\n",
        "# # 1. Download the SQL script from GitHub\n",
        "# sql_url = 'https://raw.githubusercontent.com/pthom/northwind_psql/master/northwind.sql'\n",
        "# try:\n",
        "#     response = requests.get(sql_url)\n",
        "#     response.raise_for_status()  # Raise an exception for bad status codes\n",
        "#     sql_script = response.text\n",
        "#     print(\"SQL script downloaded successfully.\")\n",
        "# except requests.exceptions.RequestException as e:\n",
        "#     print(f\"Error downloading script: {e}\")\n",
        "#     sql_script = None\n",
        "\n",
        "# # 2. Connect to your Render PostgreSQL database and execute the script\n",
        "# if sql_script:\n",
        "#     # Replace with your actual database credentials from Render\n",
        "\n",
        "#     try:\n",
        "#         # Connect to the database\n",
        "#         conn = psycopg2.connect(db_url)\n",
        "#         conn.autocommit = True  # Set autocommit to true to run the script commands immediately\n",
        "#         cursor = conn.cursor()\n",
        "#         print(\"Database connection successful. Executing script...\")\n",
        "\n",
        "#         # Execute the entire SQL script\n",
        "#         cursor.execute(sql_script)\n",
        "\n",
        "#         print(\"Northwind database script executed successfully.\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"An error occurred: {e}\")\n",
        "\n",
        "#     finally:\n",
        "#         # Clean up the connection\n",
        "#         if 'cursor' in locals():\n",
        "#             cursor.close()\n",
        "#         if 'conn' in locals():\n",
        "#             conn.close()\n",
        "#         print(\"Database connection closed.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "g_QROze69siL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "try:\n",
        "    # Create a database engine\n",
        "    engine = create_engine(db_url)\n",
        "    print(\"Successfully created database engine.\")\n",
        "\n",
        "    # Connect to the database\n",
        "    with engine.connect() as connection:\n",
        "        print(\"Database connection successful. Running verification queries...\")\n",
        "\n",
        "        # --- Verification Query 1: List all tables ---\n",
        "        # This confirms that the tables were created by the script.\n",
        "        print(\"\\n--- Verifying table creation ---\")\n",
        "        list_tables_query = text(\"\"\"\n",
        "            SELECT tablename\n",
        "            FROM pg_catalog.pg_tables\n",
        "            WHERE schemaname != 'pg_catalog' AND\n",
        "                  schemaname != 'information_schema';\n",
        "        \"\"\")\n",
        "        tables_df = pd.read_sql(list_tables_query, connection)\n",
        "        print(\"Tables found in the database:\")\n",
        "        print(tables_df)\n",
        "\n",
        "        # --- Verification Query 2: Count rows in the 'customers' table ---\n",
        "        # This confirms that data was inserted.\n",
        "        print(\"\\n--- Verifying row count in 'customers' table ---\")\n",
        "        count_query = text(\"SELECT COUNT(*) FROM customers;\")\n",
        "        row_count = connection.execute(count_query).scalar()\n",
        "        print(f\"Number of rows in 'customers' table: {row_count}\")\n",
        "        # The Northwind script should insert 91 customers.\n",
        "\n",
        "        # --- Verification Query 3: Select a sample of data from the 'products' table ---\n",
        "        # This allows for a visual inspection of the data.\n",
        "        print(\"\\n--- Displaying sample data from 'products' table ---\")\n",
        "        sample_data_query = text(\"SELECT * FROM products LIMIT 5;\")\n",
        "        products_df = pd.read_sql(sample_data_query, connection)\n",
        "        print(\"Sample of data from the 'products' table:\")\n",
        "        print(products_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "\n",
        "finally:\n",
        "    if 'engine' in locals():\n",
        "        engine.dispose()\n",
        "        print(\"\\nDatabase connection closed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfF86mnA-GfA",
        "outputId": "6d2ba8cf-d4ca-45fa-8bac-fa1e57bed55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created database engine.\n",
            "Database connection successful. Running verification queries...\n",
            "\n",
            "--- Verifying table creation ---\n",
            "Tables found in the database:\n",
            "                 tablename\n",
            "0                us_states\n",
            "1                customers\n",
            "2                   orders\n",
            "3                employees\n",
            "4                 shippers\n",
            "5                 products\n",
            "6               categories\n",
            "7                suppliers\n",
            "8                   region\n",
            "9              territories\n",
            "10    employee_territories\n",
            "11   customer_demographics\n",
            "12  customer_customer_demo\n",
            "13           order_details\n",
            "\n",
            "--- Verifying row count in 'customers' table ---\n",
            "Number of rows in 'customers' table: 91\n",
            "\n",
            "--- Displaying sample data from 'products' table ---\n",
            "Sample of data from the 'products' table:\n",
            "   product_id                  product_name  supplier_id  category_id  \\\n",
            "0           1                          Chai            8            1   \n",
            "1           2                         Chang            1            1   \n",
            "2           3                 Aniseed Syrup            1            2   \n",
            "3           4  Chef Anton's Cajun Seasoning            2            2   \n",
            "4           5        Chef Anton's Gumbo Mix            2            2   \n",
            "\n",
            "     quantity_per_unit  unit_price  units_in_stock  units_on_order  \\\n",
            "0   10 boxes x 30 bags       18.00              39               0   \n",
            "1   24 - 12 oz bottles       19.00              17              40   \n",
            "2  12 - 550 ml bottles       10.00              13              70   \n",
            "3       48 - 6 oz jars       22.00              53               0   \n",
            "4             36 boxes       21.35               0               0   \n",
            "\n",
            "   reorder_level  discontinued  \n",
            "0             10             1  \n",
            "1             25             1  \n",
            "2             25             0  \n",
            "3              0             0  \n",
            "4              0             1  \n",
            "\n",
            "Database connection closed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk5NqQTYQM_B",
        "outputId": "d8af0fb5-473a-49a6-8219-f8e6b8fda870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "qjAtBcdUfKPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Configure the LangChain client to connect to the local MCP server\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# The server started by npx runs on localhost:8000 within the Colab environment\n",
        "client = MultiServerMCPClient(\n",
        "    {\n",
        "        \"postgres\": {\n",
        "          \"url\": \"your_hosted_mcp_server_url\",\n",
        "            \"transport\": \"sse\",\n",
        "        }\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"MCP Client configured. You can now get tools and create your agent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhE7Vp8dG-1v",
        "outputId": "1117ed63-e48b-441d-b4bb-2c4b557eb382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCP Client configured. You can now get tools and create your agent.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Asynchronously get the tools from the client\n",
        "tools = await client.get_tools()\n",
        "\n",
        "from pprint import pprint\n",
        "pprint(tools)"
      ],
      "metadata": {
        "id": "DXA5AFuk1Ih2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6068889-4e37-4405-f125-c7327b1577c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[StructuredTool(name='list_schemas', description='List all schemas in the database', args_schema={'properties': {}, 'title': 'list_schemasArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a71a0>),\n",
            " StructuredTool(name='list_objects', description='List objects in a schema', args_schema={'properties': {'schema_name': {'description': 'Schema name', 'title': 'Schema Name', 'type': 'string'}, 'object_type': {'default': 'table', 'description': \"Object type: 'table', 'view', 'sequence', or 'extension'\", 'title': 'Object Type', 'type': 'string'}}, 'required': ['schema_name'], 'title': 'list_objectsArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7e20>),\n",
            " StructuredTool(name='get_object_details', description='Show detailed information about a database object', args_schema={'properties': {'schema_name': {'description': 'Schema name', 'title': 'Schema Name', 'type': 'string'}, 'object_name': {'description': 'Object name', 'title': 'Object Name', 'type': 'string'}, 'object_type': {'default': 'table', 'description': \"Object type: 'table', 'view', 'sequence', or 'extension'\", 'title': 'Object Type', 'type': 'string'}}, 'required': ['schema_name', 'object_name'], 'title': 'get_object_detailsArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7a60>),\n",
            " StructuredTool(name='explain_query', description='Explains the execution plan for a SQL query, showing how the database will execute it and provides detailed cost estimates.', args_schema={'properties': {'sql': {'description': 'SQL query to explain', 'title': 'Sql', 'type': 'string'}, 'analyze': {'default': False, 'description': 'When True, actually runs the query to show real execution statistics instead of estimates. Takes longer but provides more accurate information.', 'title': 'Analyze', 'type': 'boolean'}, 'hypothetical_indexes': {'default': [], 'description': 'A list of hypothetical indexes to simulate. Each index must be a dictionary with these keys:\\n    - \\'table\\': The table name to add the index to (e.g., \\'users\\')\\n    - \\'columns\\': List of column names to include in the index (e.g., [\\'email\\'] or [\\'last_name\\', \\'first_name\\'])\\n    - \\'using\\': Optional index method (default: \\'btree\\', other options include \\'hash\\', \\'gist\\', etc.)\\n\\nExamples: [\\n    {\"table\": \"users\", \"columns\": [\"email\"], \"using\": \"btree\"},\\n    {\"table\": \"orders\", \"columns\": [\"user_id\", \"created_at\"]}\\n]\\nIf there is no hypothetical index, you can pass an empty list.', 'items': {'additionalProperties': True, 'type': 'object'}, 'title': 'Hypothetical Indexes', 'type': 'array'}}, 'required': ['sql'], 'title': 'explain_queryArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7880>),\n",
            " StructuredTool(name='analyze_workload_indexes', description='Analyze frequently executed queries in the database and recommend optimal indexes', args_schema={'properties': {'max_index_size_mb': {'default': 10000, 'description': 'Max index size in MB', 'title': 'Max Index Size Mb', 'type': 'integer'}, 'method': {'default': 'dta', 'description': 'Method to use for analysis', 'enum': ['dta', 'llm'], 'title': 'Method', 'type': 'string'}}, 'title': 'analyze_workload_indexesArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7920>),\n",
            " StructuredTool(name='analyze_query_indexes', description='Analyze a list of (up to 10) SQL queries and recommend optimal indexes', args_schema={'properties': {'queries': {'description': 'List of Query strings to analyze', 'items': {'type': 'string'}, 'title': 'Queries', 'type': 'array'}, 'max_index_size_mb': {'default': 10000, 'description': 'Max index size in MB', 'title': 'Max Index Size Mb', 'type': 'integer'}, 'method': {'default': 'dta', 'description': 'Method to use for analysis', 'enum': ['dta', 'llm'], 'title': 'Method', 'type': 'string'}}, 'required': ['queries'], 'title': 'analyze_query_indexesArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7100>),\n",
            " StructuredTool(name='analyze_db_health', description=\"Analyzes database health. Here are the available health checks:\\n- index - checks for invalid, duplicate, and bloated indexes\\n- connection - checks the number of connection and their utilization\\n- vacuum - checks vacuum health for transaction id wraparound\\n- sequence - checks sequences at risk of exceeding their maximum value\\n- replication - checks replication health including lag and slots\\n- buffer - checks for buffer cache hit rates for indexes and tables\\n- constraint - checks for invalid constraints\\n- all - runs all checks\\nYou can optionally specify a single health check or a comma-separated list of health checks. The default is 'all' checks.\", args_schema={'properties': {'health_type': {'default': 'all', 'description': 'Optional. Valid values are: all, buffer, connection, constraint, index, replication, sequence, vacuum.', 'title': 'Health Type', 'type': 'string'}}, 'title': 'analyze_db_healthArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7240>),\n",
            " StructuredTool(name='get_top_queries', description=\"Reports the slowest or most resource-intensive queries using data from the 'pg_stat_statements' extension.\", args_schema={'properties': {'sort_by': {'default': 'resources', 'description': \"Ranking criteria: 'total_time' for total execution time or 'mean_time' for mean execution time per call, or 'resources' for resource-intensive queries\", 'title': 'Sort By', 'type': 'string'}, 'limit': {'default': 10, 'description': 'Number of queries to return when ranking based on mean_time or total_time', 'title': 'Limit', 'type': 'integer'}}, 'title': 'get_top_queriesArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a77e0>),\n",
            " StructuredTool(name='execute_sql', description='Execute any SQL query', args_schema={'properties': {'sql': {'default': 'all', 'description': 'SQL to run', 'title': 'Sql', 'type': 'string'}}, 'title': 'execute_sqlArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7b8f911a7ba0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    api_key=userdata.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "    azure_endpoint=userdata.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    openai_api_version=userdata.get(\"AZURE_OPENAI_VERSION\"),\n",
        "    azure_deployment=\"gpt-4.1\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        ")"
      ],
      "metadata": {
        "id": "PuCjzSszg6wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    tools = await client.get_tools()\n",
        "    agent = create_react_agent(llm, tools, checkpointer=checkpointer)\n",
        "    config = {\"configurable\": {\"thread_id\": \"user-convo-123\"}}\n",
        "\n",
        "    # First question\n",
        "    print(\"\\n--- Turn 1 ---\")\n",
        "    q1 = \"How many customers are in the customers table?\"\n",
        "    async for event in agent.astream_events({\"messages\": [{\"role\": \"user\", \"content\": q1}]}, config=config, version=\"v1\"):\n",
        "        if event[\"event\"] == \"on_chat_model_stream\" and event[\"data\"][\"chunk\"][\"content\"]:\n",
        "            print(event[\"data\"][\"chunk\"][\"content\"], end=\"\", flush=True)\n",
        "\n",
        "    # Follow-up, demonstrating memory\n",
        "    print(\"\\n\\n--- Turn 2 ---\")\n",
        "    q2 = \"And how many orders are there?\"\n",
        "    async for event in agent.astream_events({\"messages\": [{\"role\": \"user\", \"content\": q2}]}, config=config, version=\"v1\"):\n",
        "        if event[\"event\"] == \"on_chat_model_stream\" and event[\"data\"][\"chunk\"][\"content\"]:\n",
        "            print(event[\"data\"][\"chunk\"][\"content\"], end=\"\", flush=True)\n",
        "\n",
        "await main()"
      ],
      "metadata": {
        "id": "W-6t0OQPN48P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}